import numpy as np
from numba import njit

def random_vector_spherical(N, half_sphere=False):
    """
    Generate N uniformly distributed random points on the surface of a sphere of radius 1.
    
    Parameters
    ----------
    N : int
        Number of random poits to sample
    half_sphere : bool
        Whether to sample only half the sphere. Default: False
    
    Returns
    -------
    points : array[float]
    """
    np.random.seed()
    
    phi = np.random.uniform(0, 2 * np.pi, size=N)
    cos_theta = np.random.uniform(-1, 1, size=N) if ~half_sphere else np.random.uniform(0, 1, size=N)
    theta = np.arccos(cos_theta)
    
    x =  np.sin(theta) * np.cos(phi)
    y =  np.sin(theta) * np.sin(phi)
    z =  cos_theta
    
    return np.vstack((x, y, z)).T

def gram_schmidt(los):
    """Applies the Gram-Schmidt procedure to find a cartesian orthonormal coordinate basis where e_x=los.
    As initial cartesian basis the following vectors are chosen:

                    v1 = los;
                    v2 = los + [0,1,0];
                    v3 = los + [0,0,1];
                    
    This produces an initial basis that is suitable for orthonormalization, given any line of sight vector.
    The function returns the P = MÂ·P', M matrix, i.e. the change of basis matrix from the los coordinates to
    the canonical basis.

    The change of basis matrix -new basis vectors, in cols- can be used to change coordinates from different cartesian coordinate
    systems. Physically, this is usefull to produce projections of halo/galaxies at different lines of sights.
    
    Parameters
    ----------
    mlos : array[float], shape=(3,)
        Array containing one, lines of sight. E.g. one row of the array generated by  running random_vector_spherical.

    Returns
    -------
    basis_matrix : array[float], shape(3,3)
    """
    dims = len(los)
    if np.all(los == [1,0,0]):
        return np.identity(3)
    if np.all(los == [0,1,0]):
        return np.array([[0., 0., 1.],
                         [1., 0., 0.],
                         [0., 1., 0.]])
    if np.all(los == [0,0,1]):
        return np.array([[0., 1., 0.],
                         [0., 0., 1.],
                         [1., 0., 0.]])
        
    basis_matrix = np.identity(dims) + np.random.rand(3,3) * 1E-12
    basis_matrix = (basis_matrix + np.array(los)/np.linalg.norm(los)).T
    basis_matrix[:, 0] = np.array(los)/np.linalg.norm(los)
    
    for i in range(1, dims):
        gs_coef = np.array([ np.dot(basis_matrix[:, i], basis_matrix[:, j] )  / np.dot( basis_matrix[:, j], basis_matrix[:, j] ) for j in range(i)])
        basis_matrix[:, i] = basis_matrix[:, i] - np.array([gs_coef[j] * basis_matrix[:,j] for j in range(i)]).sum(axis=0)
        basis_matrix[:, i] = basis_matrix[:, i] / np.linalg.norm(basis_matrix[:, i])
        
    return basis_matrix

def vectorized_base_change(matrix, vector_quantity):
    """Vectorized Matrix-Vector multiplication.
    """
    vq = vector_quantity.value
    def _njitted_vec(matrix, vecs):
        changed_vectors =  np.empty_like(vecs)
        for i in range(len(vecs)):
            changed_vectors[i, :] = np.dot(matrix, vecs[i,:])

        return changed_vectors

    new_basis_vectors = _njitted_vec(matrix, vq)
    try:
        return new_basis_vectors * vector_quantity.units
    except:
        return new_basis_vector
    
def easy_los_velocity(vel, los):
    """Computes the Line of Sight Velocity of particles along a given LOS. In principle this could be done by changing basis using
    the Gram-Schmidt function  and looking at the first component of the resulting velocities (those aligned with the l.o.s. as 
    defined in the GS implementation above). Readability wise this is easier.

    Parameters
    ----------
    vel : array
        Array of velocities. Shape (N,3).
    los : array
        Array of shape (3,) representing the LOS. May not be normalized.

    Returns
    -------
    projected_vel : array
        Array of projected velocity magnitudes along the LOS.
    """

    los = los / np.linalg.norm(los)
    return np.dot(vel, los)
    
def softmax(vals, T=1):
    """Softmax function for computing weights for various applications.
    T~0.25 works well for gravitational purposes, when many particles are present. Not so great when few particles are present
    because it produces a sharped peak around few of the *already* few particles. Use (for gravitational purposes): T~2/3* sum(kin)/min(E)
    instead.

    More stable than the usuan N-most-bound particles, specially when combined with changing temperature.
    
    Parameters
    ----------
    vals : array
        Quantity tobe weigthed with
    T : float
        Temperature used for the wheighting. Default: 1
    """
    exp_vals = np.exp((vals - np.max(vals))/T)  
    return exp_vals / np.sum(exp_vals)

def add_bins(bin_edges, max_value):
    """Extends the bin_edges array until max_value is reached, with a bin spacing of 
    delta log(r_e) = mean( log(r_i+1) - log(r_i) )
    """
    if bin_edges is None:
        return None
    bin_edges = np.asarray(bin_edges)
    
    if not np.all(bin_edges[:-1] < bin_edges[1:]):
        raise ValueError("bin_edges must be sorted in ascending order.")
    if np.any(bin_edges <= 0):
        raise ValueError("bin_edges must contain only positive values.")
    if max_value <= bin_edges[-1]:
        raise ValueError("max_value must be greater than the largest initial bin edge.")

    log_deltas = np.log(bin_edges[1:] / bin_edges[:-1])
    mean_log_delta = np.mean(log_deltas)
    
    current_edge = bin_edges[-1]
    extended_bins = [current_edge]
    
    while current_edge < max_value:
        next_edge = current_edge * np.exp(mean_log_delta)
        if next_edge >= max_value:
            next_edge = max_value
        extended_bins.append(next_edge)
        if next_edge == max_value:
            break
        current_edge = next_edge

    return np.concatenate([bin_edges, extended_bins[1:]])



